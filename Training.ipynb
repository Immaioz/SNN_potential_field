{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8949f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import snntorch as snn\n",
    "\n",
    "# === Modello SNN ===\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self,num_inputs,num_hidden, num_outputs, num_steps=25,beta=0.95):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_steps = num_steps\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.num_inputs,self.num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=self.beta)\n",
    "        self.fc2 = nn.Linear(self.num_hidden, self.num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=self.beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        \n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd1289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\anton\\\\Documents\\\\PhD\\\\Spiking\\\\PotentialField_Sim\\\\simulation_data\\\\simulation_log.csv')\n",
    "sensor_df = df[[col for col in df.columns if 'sensor' in col]]  \n",
    "sensor_df = pd.concat([df[\"run\"], sensor_df], axis=1)\n",
    "# sensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf55509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class utils:\n",
    "    @staticmethod\n",
    "    def preprocess(image):\n",
    "        return cv2.resize(image, (512, 512))\n",
    "\n",
    "    @staticmethod\n",
    "    def low_res(image):\n",
    "        return utils.preprocess(image)[0::12, 0::12]\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_predict(image):\n",
    "        return np.expand_dims(utils.preprocess(tf.keras.applications.vgg19.preprocess_input(image)), axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def acquire_image(path):\n",
    "        return cv2.imread(path,0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_2828(image):\n",
    "        return cv2.resize(image, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a614a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 994/994 [00:00<00:00, 6040.95it/s]\n",
      "100%|██████████| 1602/1602 [00:00<00:00, 6011.08it/s]\n",
      "100%|██████████| 1968/1968 [00:00<00:00, 5878.05it/s]\n",
      "100%|██████████| 1576/1576 [00:00<00:00, 5686.56it/s]\n",
      "100%|██████████| 1561/1561 [00:00<00:00, 6012.72it/s]\n",
      "100%|██████████| 1425/1425 [00:00<00:00, 6323.74it/s]\n",
      "100%|██████████| 2025/2025 [00:00<00:00, 6249.22it/s]\n",
      "100%|██████████| 3354/3354 [00:00<00:00, 6374.09it/s]\n",
      "100%|██████████| 1068/1068 [00:00<00:00, 6477.68it/s]\n",
      "100%|██████████| 1333/1333 [00:00<00:00, 6226.25it/s]\n",
      "100%|██████████| 2303/2303 [00:00<00:00, 6321.98it/s]\n",
      "100%|██████████| 1610/1610 [00:00<00:00, 6437.35it/s]\n",
      "100%|██████████| 1973/1973 [00:00<00:00, 6433.67it/s]\n",
      "100%|██████████| 2641/2641 [00:00<00:00, 5811.99it/s]\n",
      "100%|██████████| 1777/1777 [00:00<00:00, 6088.67it/s]\n",
      "100%|██████████| 2485/2485 [00:00<00:00, 6055.97it/s]\n",
      "100%|██████████| 2673/2673 [00:00<00:00, 5887.60it/s]\n",
      "100%|██████████| 2251/2251 [00:00<00:00, 5973.13it/s]\n",
      "100%|██████████| 1233/1233 [00:00<00:00, 6341.91it/s]\n",
      "100%|██████████| 1508/1508 [00:00<00:00, 6149.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm   \n",
    "\n",
    "img_path = \"C:\\\\Users\\\\anton\\\\Documents\\\\PhD\\\\Spiking\\\\PotentialField_Sim\\\\simulation_data\\\\\"\n",
    "dirs = os.listdir(img_path)\n",
    "dirs.sort()\n",
    "\n",
    "tot_images = []\n",
    "\n",
    "for item in dirs:\n",
    "    if item.endswith(\".csv\"):\n",
    "        continue\n",
    "    else:\n",
    "        run_path = os.path.join(img_path, item)\n",
    "        images = []\n",
    "\n",
    "        for img_file in tqdm(os.listdir(run_path)):\n",
    "            if img_file.endswith(\".png\"):\n",
    "                image = utils.acquire_image(os.path.join(run_path, img_file))\n",
    "                low_res_image = utils.preprocess_2828(image)\n",
    "                images.append(low_res_image)\n",
    "        tot_images.append(np.array(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e1808135",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = []\n",
    "for i in range(len(tot_images)):\n",
    "    for n in range(len(tot_images[i])):\n",
    "        run.append(i)\n",
    "run = np.array(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img = np.concatenate(tot_images, axis=0)\n",
    "\n",
    "np.save('X_img.npy', X_img)\n",
    "np.save('run.npy', run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bc91c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_img = np.load('X_img.npy')\n",
    "run = np.load('run.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb2236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,val_dataloader,epochs,loss_fn,optimizer):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_batch = iter(train_dataloader)\n",
    "    \n",
    "        train_loss_epoch = 0\n",
    "        val_loss_epoch = 0\n",
    "    \n",
    "        for data, targets in tqdm(train_batch):\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "        \n",
    "            model.train()\n",
    "            spk_rec, mem_rec = model(data.view(len(data), -1))\n",
    "\n",
    "            loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "            for step in range(model.num_steps):\n",
    "                loss_val += loss_fn(mem_rec[step], targets)\n",
    "\n",
    "\n",
    "            loss_val = loss_val / model.num_steps\n",
    "                #spk_rec\n",
    "         \n",
    "            train_loss_epoch += loss_val.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                val_data, val_targets = next(iter(val_dataloader))\n",
    "                val_data = val_data.to(device)\n",
    "                val_targets = val_targets.to(device)\n",
    "\n",
    "                val_spk, val_mem = model(val_data.view(len(val_data), -1))\n",
    "\n",
    "                val_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "                for step in range(model.num_steps):\n",
    "                    val_loss += loss_fn(val_mem[step], val_targets)\n",
    "                    #val_spk\n",
    "\n",
    "                val_loss = val_loss / model.num_steps\n",
    "          \n",
    "                #recon = torch.mean(val_mem,axis=0)\n",
    "                #val_loss = loss_fn(recon,val_targets)\n",
    "        \n",
    "            val_loss_epoch += val_loss.item()\n",
    "        \n",
    "        print(f\"Train loss at epoch: {e+1}: {train_loss_epoch}\")\n",
    "        print(f\"Val loss at epoch: {e+1}: {val_loss_epoch}\")\n",
    "    \n",
    "        train_losses.append(train_loss_epoch)\n",
    "        val_losses.append(val_loss_epoch)\n",
    "    \n",
    "    return train_losses,val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a9d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immagini caricate: torch.Size([37360, 784])\n",
      "Sensori caricati: torch.Size([37360, 16])\n"
     ]
    }
   ],
   "source": [
    "X_img_tensor = torch.tensor(X_img).unsqueeze(1)  # [N, 1, 28, 28]\n",
    "X_img_tensor = X_img_tensor.view(len(X_img_tensor), -1)  # [N, 784]\n",
    "print(\"Immagini caricate:\", X_img_tensor.shape)\n",
    "X_sensors = sensor_df.iloc[:,1:].to_numpy()\n",
    "X_sensors = torch.tensor(X_sensors, dtype=torch.float32)\n",
    "print(\"Sensori caricati:\", X_sensors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48091ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573ec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45a4081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled = scaler.fit_transform(X_img_tensor)\n",
    "\n",
    "\n",
    "X_sensor_tensor = torch.tensor(sensor_df.iloc[:,1:].to_numpy(), dtype=torch.float32)\n",
    "# X_sensor_tensor.shape\n",
    "\n",
    "\n",
    "X_img_tensor_scaled = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "X_total = torch.concat((X_img_tensor_scaled, X_sensor_tensor), axis=-1)\n",
    "\n",
    "run_elements = np.bincount(run)\n",
    "run_elements\n",
    "test_run = np.sum(run_elements[-2:])\n",
    "val_run = np.sum(run_elements[-4:-2])\n",
    "train_run = np.sum(run_elements[:-4])\n",
    "\n",
    "#  Split 80/20\n",
    "N_train = train_run\n",
    "N_val = val_run\n",
    "N_test = test_run\n",
    "\n",
    "X_train = X_total[:N_train]\n",
    "X_val = X_total[N_train:N_train+N_val]\n",
    "X_test = X_total[N_train+N_val:N_train+N_val+N_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6429317",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ff19512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:49<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch: 1: 33.23077738285065\n",
      "Val loss at epoch: 1: 28.890399426221848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:49<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch: 2: 21.771459475159645\n",
      "Val loss at epoch: 2: 21.289051726460457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:50<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch: 3: 22.19031612575054\n",
      "Val loss at epoch: 3: 21.69804534316063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:48<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch: 4: 21.256640881299973\n",
      "Val loss at epoch: 4: 21.33943897485733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:50<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch: 5: 20.58378331363201\n",
      "Val loss at epoch: 5: 20.54596820473671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:49<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch: 6: 19.843179687857628\n",
      "Val loss at epoch: 6: 19.803601056337357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:46<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch: 7: 19.371784642338753\n",
      "Val loss at epoch: 7: 19.198521986603737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 15/116 [00:05<00:34,  2.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m loss_fn = torch.nn.MSELoss()\n\u001b[32m     16\u001b[39m optimizer = torch.optim.Adam(SpikingAE.parameters(), lr=\u001b[32m1e-3\u001b[39m, betas=(\u001b[32m0.9\u001b[39m, \u001b[32m0.999\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m train_losses, val_losses = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSpikingAE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_dataloader, val_dataloader, epochs, loss_fn, optimizer)\u001b[39m\n\u001b[32m     27\u001b[39m train_loss_epoch += loss_val.item()\n\u001b[32m     29\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mloss_val\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m optimizer.step()\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anton\\Documents\\PhD\\Spiking\\.venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anton\\Documents\\PhD\\Spiking\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anton\\Documents\\PhD\\Spiking\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anton\\Documents\\PhD\\Spiking\\.venv\\Lib\\site-packages\\torch\\autograd\\function.py:292\u001b[39m, in \u001b[36mBackwardCFunction.apply\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBackwardCFunction\u001b[39;00m(_C._FunctionBase, FunctionCtx, _HookMixin):\n\u001b[32m    288\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[33;03m    This class is used for internal autograd work. Do not use.\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m    293\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03m        Apply method used when executing this Node during the backward\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[33;03m        \"\"\"\u001b[39;00m\n\u001b[32m    296\u001b[39m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[32m    297\u001b[39m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = TensorDataset(X_train, X_train)\n",
    "test_dataset = TensorDataset(X_test, X_test)\n",
    "\n",
    "# CREA DATALOADER\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# SpikingAE = SAE(X_train.shape[-1],500,num_steps=30)\n",
    "SpikingAE = SAE(num_inputs= (28*28) + 16 , num_hidden=500, num_outputs= (28*28)+16, num_steps=25, beta=0.95)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(SpikingAE.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "train_losses, val_losses = train(SpikingAE,train_loader,test_loader,50,loss_fn,optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
